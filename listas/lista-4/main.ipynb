{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKP8366 - TÓPICOS AVANÇADOS - APRENDIZAGEM DE MÁQUINA PROBABILÍSTICA\n",
    "\n",
    "<img  src=\"https://img.shields.io/badge/UFC_CKP8366-VAUX GOMES-000000?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAANgAAADYBsVpjYQAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAAENSURBVCiRbdFBS9QBEAXw36y7Wq6IgUSGsixhJBpiRBB08XN7ETyIFyPYui2KBXsQTUphsbbx4Cz8E+cyw8ybN/NmQsMy8xO+YRkdXGA9Ig6g3QC+r/Ad/lS8hp9TTKtBvFB+Dt2qZXNyuxEnNnCORUQ1Xj8G/lX7trAfEVeZOYu3j63xDG8wg35mdiPiFpf/gTNzocZ+xQgv8KGYp3WRmTtYxQBPiv0Wh5W/wjaG7WI8K1HThlPsYowevmO+hZe4wfOImJTIV5jgafl/WInM3MBmMY5xXP41ltx/cgaDKAF999/q1L0/Yq9ygc8RMWxBRJzgN7bwF8PS0MNpRAwf3nlUAo/qdAf4gh9TwB2yEFM5Ddb+rgAAAABJRU5ErkJggg==\" /> <img src=\"https://img.shields.io/badge/Jupyter-000000?style=for-the-badge&logo=jupyter&logoColor=white\" /> <img src=\"https://img.shields.io/badge/Python-000000?style=for-the-badge&logo=python&logoColor=white\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Principal Components Analysis (PPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticPCA:\n",
    "  def __init__(self, L, epochs=50, epsilon=0, seed=42):\n",
    "    self.L = L\n",
    "    self.epochs = epochs\n",
    "    self.epsilon = epsilon\n",
    "    self.seed = seed\n",
    "    \n",
    "  def fit(self, X, verbose=False):\n",
    "    N, D = X.shape\n",
    "    np.random.seed(self.seed)\n",
    "    \n",
    "    # Safety\n",
    "    L = min(max(1, self.L), D)\n",
    "    \n",
    "    # Step 1.1\n",
    "    mu = np.mean(X, axis=0)\n",
    "    W = np.random.normal(0, 0.1, size=(D, L))\n",
    "    sigma2 = np.var(X, axis=0).mean() + self.epsilon # Variância média\n",
    "    \n",
    "    #\n",
    "    likelihoods = np.zeros(self.epochs)\n",
    "    \n",
    "    # Debug\n",
    "    if verbose:\n",
    "      print(mu.shape, W.shape, sigma2, self.epsilon)\n",
    "    \n",
    "    for e in range(self.epochs):\n",
    "      # Step E / Step 2.1\n",
    "      Minv = np.linalg.inv(W.T @ W + sigma2 + np.eye(L))\n",
    "      MinvWT = Minv @ W.T\n",
    "      \n",
    "      # Debug\n",
    "      if verbose and e == 0:\n",
    "        print(Minv.shape, MinvWT.shape)\n",
    "\n",
    "      Ez = np.empty((N, L))\n",
    "      EzzT = np.empty((N, L, L))\n",
    "      \n",
    "      for i in range(N):\n",
    "        Ez[i] = MinvWT @ (X[i] - mu)\n",
    "        EzzT[i] = (sigma2 * Minv) + Ez[i] @ Ez[i].T\n",
    "        \n",
    "      # Debug\n",
    "      if verbose and e == 0:\n",
    "        print(Ez.shape, EzzT.shape)\n",
    "        \n",
    "      # Step M / Step 2.2\n",
    "      W = np.empty((N, D, L))\n",
    "      sigma2 = self.epsilon\n",
    "      \n",
    "      for i in range(N):\n",
    "        W[i] = np.outer((X[i] - mu), Ez[i])\n",
    "        \n",
    "      W = np.sum(W, axis=0) @ np.linalg.inv(np.sum(EzzT, axis=0))\n",
    "      \n",
    "      #\n",
    "      sigma2 = 2\n",
    "      \n",
    "      for i in range(N):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6313, 784)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "X = np.genfromtxt('./files/mnist_5.csv', delimiter=',')\n",
    "\n",
    "# Normalization MinMax Keeping the only zeros columns\n",
    "min_ = X.min(axis=0)\n",
    "max_ = X.max(axis=0)\n",
    "mask = min_ != max_\n",
    "\n",
    "X[:, mask] = (X[:, mask] - min_[mask]) / (max_[mask] - min_[mask])\n",
    "\n",
    "# X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) # Normalization 0 ~ 1\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,) (784, 5) 6016.445442380658\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "L = 5\n",
    "\n",
    "# fit\n",
    "N, D = X.shape\n",
    "L = min(max(1, L), D)\n",
    "likelihood = []\n",
    "\n",
    "# Step 1\n",
    "mu = np.mean(X, axis=0)\n",
    "W = np.random.normal(0, 0.1, size=(D, L))\n",
    "sigma2 = np.var(X)\n",
    "\n",
    "# Debug\n",
    "print(mu.shape, W.shape, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5) (5, 784)\n",
      "(6313, 5) (6313, 5, 5)\n",
      "(784, 5) 54566441886104.33\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1 (Expectation)\n",
    "Minv = np.linalg.inv(W.T @ W + sigma2 * np.eye(L))\n",
    "MinvWT = Minv @ W.T\n",
    "\n",
    "# Debug\n",
    "print(Minv.shape, MinvWT.shape)\n",
    "\n",
    "Ez = np.empty((N, L))\n",
    "EzzT = np.empty((N, L, L))\n",
    "\n",
    "for i in range(N):\n",
    "  Ez[i] = MinvWT @ (X[i] - mu)\n",
    "  EzzT[i] = (sigma2 * Minv) + Ez[i] @ Ez[i].T\n",
    "  \n",
    "# Debug\n",
    "print(Ez.shape, EzzT.shape)\n",
    "\n",
    "# Step 2.2 (Maximization)\n",
    "W = np.empty((N, D, L))\n",
    "\n",
    "for i in range(N):\n",
    "  W[i] = np.outer((X[i] - mu), Ez[i])\n",
    "\n",
    "W = np.sum(W, axis=0) @ np.linalg.inv(np.sum(EzzT, axis=0))\n",
    "\n",
    "# Ou\n",
    "# W = np.einsum('ni,nj->ij', X - mu, Ez) @ np.linalg.inv(np.einsum('nij->ij', EzzT))\n",
    "\n",
    "#\n",
    "sigma2 = 0\n",
    "\n",
    "for i in range(N):\n",
    "  sigma2 += np.linalg.norm(X[i] - mu) - (2 * Ez[i].T @ W.T @ (X[i]- mu)) + np.linalg.trace(EzzT[i] @ W.T @ W)\n",
    "\n",
    "sigma2 /= 1 / (N * D)\n",
    "\n",
    "# Debug\n",
    "print(W.shape, sigma2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-2.6637497359477565e+23)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Likelihood\n",
    "epsilon = 1e-6\n",
    "M = W.T @ W + (sigma2 + epsilon) * np.eye(L)\n",
    "\n",
    "Sigma = W @ W.T + sigma2 * np.eye(D)\n",
    "SigmaInv = 0.5 * sigma2 * np.eye(D) -0.5 * sigma2 * (W @ np.linalg.inv(M) @ W.T) # Usando identidade de Woodbury\n",
    "logdet = 2 * np.sum(np.log(np.diag(np.linalg.cholesky(Sigma)))) # Usando Cholesky\n",
    " \n",
    "part = 0\n",
    "\n",
    "for i in range(N):\n",
    "  diff = X[i] - mu\n",
    "  part += diff @ SigmaInv @ diff\n",
    "  \n",
    "likelihood.append((-0.5 * (N * D) * np.log(2 * np.pi)) - (0.5 * N * logdet) - (0.5 * part))\n",
    "likelihood[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(-1.1286202273565767e+23),\n",
       " np.float64(-2.6637497359477565e+23),\n",
       " np.float64(-2.6637497359477565e+23)]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
